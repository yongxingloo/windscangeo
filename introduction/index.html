
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../examples/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Introduction - WindScanGEO</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="WindScanGEO" class="md-header__button md-logo" aria-label="WindScanGEO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            WindScanGEO
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label=""  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="WindScanGEO" class="md-nav__button md-logo" aria-label="WindScanGEO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    WindScanGEO
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    WindScanGEO
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../validation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Validation and biases
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Install
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../example_notebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tutorial WindScanGEO
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="introduction">Introduction</h1>
<p>Wind speed is a key variable in weather forecasting (<a href="https://www.sciencedirect.com/science/article/pii/S0273117724010731?casa_token=pdcyInRErvwAAAAA:Gk4MEsp3DpgqFf5Rmtx4JKUmwDfyY3MW5RZJQwmHCA87UXpsoJjqtEOmWmyKc5PNA7BbgJEFkKo">Sankhala et al., 2025</a>), climate research (<a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024GL109460">Windmiller, 2024</a>) and wind energy market predictions (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0960148111002850?via%3Dihub">Foley et al., 2012</a>). Currently, polar-orbiting satellites provide the only means of observing ocean surface wind speeds globally and at scale, with most of these satellites operating in sun-synchronous orbits (<a href="https://journals.ametsoc.org/view/journals/atot/34/6/jtech-d-16-0145.1.xml">Young et al., 2017</a>), meaning that each satellite passes over the same point on Earth at approximately the same local time each day. Scatterometers are the main sources of polar orbiting wind speed data (<a href="https://www.mdpi.com/2072-4292/13/5/940?utm_source=chatgpt.com">Bentamy et al., 2021</a>). There are currently 5 operational scatterometers orbiting the earth (Figure 1). With a maximum of two overpasses per day, we are able to capture at maximum 10 measurements at any point on earth each day (<a href="https://data.marine.copernicus.eu/product/WIND_GLO_PHY_L3_NRT_012_002/description">Copernicus marine, 2025</a>). However, these observations are spatially irregular and constrained by the instrument's swath width, which typically ranges from 500 to 1,800 km across (<a href="https://scatterometer.knmi.nl/publications/pdf/osisaf_ss3_atbd.pdf">EUMETSAT, 2024</a>).</p>
<p><img alt="1749558836403" src="../image/introduction/1749558836403.png" /></p>
<p>There is a need for increased surface wind measurements, especially over the ocean, where measurements are sparse (<a href="https://repository.library.noaa.gov/pdfjs/web/viewer.html?file=https://repository.library.noaa.gov/view/noaa/22100/noaa_22100_DS1.pdf#cite.bib208">Bourassa et al., 2009).</a> The approach proposed in this framework to address this gap is to explore the use of geostationary satellites. These have a better spatio-temporal resolution (<a href="https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing/volume-16/issue-03/037501/Validation-of-geostationary-operational-environmental-satellite-16-advanced-baseline-imager/10.1117/1.JRS.16.037501.full">Xi et al, 2022</a>) but none were designed to directly capture wind speeds.</p>
<p>Geostationary satellites have a fixed orbit. They can take an image of an entire face of the earth at regular intervals. These satellites can provide data at a 10 minute temporal resolution and can provide up to 144 measurements per day or 48 during daylight (<a href="https://www.star.nesdis.noaa.gov/GOES/">NOAA, 2025</a>).</p>
<p>Deep learning models have recently proven to be able to find complex patterns in images (<a href="https://arxiv.org/abs/1505.04597">Olaf et al., 2015</a>). Multi-spectral images provided from geostationary satellites are optimal to be entered in such models (<a href="https://acp.copernicus.org/articles/25/759/2025/">Chengxin et. al</a>).</p>
<p>A method to derive wind speeds from geostationary data would increase temporal resolution by a factor of 10x and increase the extent of coverage to further than just the swath covered by the scatterometer.</p>
<p>Using supervised learning, we label data to train a model for a specific predictive task (<a href="https://acp.copernicus.org/articles/25/759/2025/">Chengxin et. al</a>). In our application, scatterometer data serves as ground truth to train a model to infer wind speeds from geostationary satellite images.</p>
<hr />
<h1 id="geostationary-operational-environmental-satellite">Geostationary Operational Environmental Satellite</h1>
<p>the Geostationary Operational Environmental Satellite East (GOES-16) is used in this framework to provide the images for wind speed retrieval (further developents of the package could include GOES West and MeteoSat (<a href="https://www.eumetsat.int/our-satellites/meteosat-series">EUMETSAT</a>)). GOES is operated by the National Oceanic and Atmospheric Administration. It can provide a full-disk image in 16 spectral bands contained in the infrared and visible spectrum. The spatial resolution is 0.5-2 km depending on the band chosen. Images are available at 10 minute intervals. (<a href="https://www.star.nesdis.noaa.gov/GOES/">NOAA, 2025</a>)</p>
<p><img alt="" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcw_oIooWTF8f6ICY0X2ifDT6tM89Po4yahAr3iwdQ1i0QVg302he5C5jCbNmEbAa_RzpLe9OcvGHB2HyQRoJKYqcTxMi9x9gYmJx0roFZUwD8C6sxYufFzK2rthwnFZsCTPqblIQ?key=b_eJswHuJ1W0IkfZJI8EdLWM" /></p>
<p>Figure 2. Geostationary satellite data at 10 minute intervals from the Geostationary Operational Environmental Satellite East (GOES-16 Channel 01(<a href="https://www.star.nesdis.noaa.gov/GOES/">NOAA, 2025</a>)</p>
<p>We use four different scatterometer satellites as ground truth for training the model. The first two, Metop-B and Metop-C, are operated by the European Organisation for the Exploitation of Meteorological Satellites (<a href="https://space.oscar.wmo.int/satellites/view/metop_b">EUMETSAT</a>) and the European Space Agency (<a href="https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/MetOp">ESA</a>). The last two, HY-2B and HY-2C, are operated by the National Satellite Ocean Application Service (<a href="http://www.nsoas.org.cn/eng/item/253.html">NSOAS</a>) and the China Academy of Space Technology (<a href="https://www.cast.cn/english/channel/1665">CAST</a>). These four satellites were selected because they have all been operational for at least 5 years (<a href="https://space.oscar.wmo.int/satellites">WMO, 2025</a>) and continue to operate today, allowing testing on historical data from recent years.</p>
<p>These 4 satellites are all scatterometers but they differ in the exact instrument configuration used, geophysical model function (CMF) and calibration process (<a href="https://www.sciencedirect.com/science/article/pii/S0034425719300963?via%3Dihub#bb0010">Wang et al., 2019</a>, <a href="https://link.springer.com/article/10.1007/s00343-015-4136-4">Li et al., 2015</a>). The GMF relates radar backscatter measurements to wind speeds. In our application, we treat all four satellites equally as ground truth sources, under the assumption that incorporating multiple independent sensors reduces potential biases  and improves dataset robustness.</p>
<p>With each satellite orbiting the earth around twice at any point in space, we can achieve a dataset with 8 measurements per day for any given location. Taking into account that the corresponding geostationary satellite used for training can only provide data during daylight, this brings our scatterometer measurements to 4x daily.</p>
<p>This provides us with a daily dataset of around 50'000 training pairs. The training images are 128x128 pixels padded images from the GOES16 satellite which correspond to the area measured by a single scatterometer pixel (Figure 3).</p>
<p>As a result of the optical view of the GOES16 satellite, pixel count and image geometry varies depending on its location on earth. Data filtering is applied on the training data to filter out night-time images, as well as images with too few pixels. The images at the edge of the focal view of GOES are also filtered out because they do not provide enough pixels for a good prediction.</p>
<hr />
<h1 id="deep-learning-models">Deep Learning Models</h1>
<p>The current framework allows the user to use 3 different types of deep learning models.</p>
<ol>
<li>CNN</li>
<li>ResNet</li>
<li>ViT</li>
</ol>
<p>The <strong>CNN</strong> is a modular model and the lightest model to run. The images go through 3 layers resulting in 64 features at each step. The kernels used for the convolutions are 3x3 with a stride of 1. Each hyperparameter can be adjusted by the user. A hyperparameter sweep has already been done in order to find the optimal hyperparamters, nevertheless. It is possible that changing the framework and different deployment setups might require a new hyperparameter choice. A training of a model on a single of data takes approx. 10mins on a desktop GPU*.</p>
<p>The <strong>ResNet</strong> model is based on the ResNet50 from @JayPatwardhan on Github (<a href="https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/ResNet/ResNet.py">Link</a>). It is based on the foundation paper : "Deep Residual Learning for Image Recognition" by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. This model is more complex than the conventional CNN due to the use of skip connections which allows the model to be much deeper whilst avoiding the vanishing gradient problem. A training of a model on a single of data takes approx. 45mins on a desktop GPU*.</p>
<p>The <strong>ViT</strong> is based on the vision transformer implementation from @Umong Sain (<a href="https://www.kaggle.com/code/umongsain/vision-transformer-from-scratch-pytorch">Link</a>). Unlike the ResNet and ViT architecture, the ViT uses the more modern transformer architecture which has been used extensively in LLMs. The ViT comes from the foundational paper : " An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" (<a href="https://arxiv.org/abs/2010.11929">A Kolesnikov et.al</a>). A training of a model on a single of data takes approx. +1hr on a desktop GPU*.</p>
<p>*tested on a NVIDIA RTX4070x. Time is indicative only, results may vary depending on exact setup.</p>
<h1 id="comparison-of-different-channels-of-goes16">Comparison of different Channels of GOES16</h1>
<p>The GOES16 satellite captures 16 different channels from visible, near-IR to IR.  The following test results show the MSE of a 10% test dataset that was never seen in training. 16 experiments were done independently, each provided with a daily dataset of a different GOES channel. The model used is a ResNet50 limited to 50 epochs with an early stopping algorithm implemented to avoid overfitting.  The results are sorted in high test MSE to low test MSE (the lower the better). These results show that C01, C09 and C06 are the channels that perform the best in this wind speed prediction task. Channels C11 and C12 present nearly no useful data to predict wind speed and therefore show a high MSE.</p>
<p><img alt="1749560446658" src="../image/introduction/1749560446658.png" /></p>
<p>C06 <strong>Cloud Particle Size</strong></p>
<p>"The centralized wavelength for this band is 2.24 µm (micrometers).</p>
<p>The cloud particle size increases as they change from liquid to ice.
This channel helps maximize the apparent difference so we can
distinguish liquid clouds from ice crystal clouds. Small particles
(liquid) appear bright while larger ice crystals appear dark. Also,
similar to the 1.6 µm band, the 2.2 µm band can be useful in determining
 hot spots at night. In fact, this channel is closer to the emitting
energy of fires than channel 5." (<a href="https://www.noaa.gov/jetstream/goes_east">NOAA</a>)</p>
<p>C09 <strong>Mid-Level water vapor</strong></p>
<p>"The centralized wavelength for this band is 6.9 µm (micrometers).</p>
<p>Unless higher-level clouds obscure the view, this band can view as
low as 500 mb level (about 18,000 feet/5,500 meters). It is used for
mid- and upper-level water vapor tracking, jet stream identification,
hurricane track forecasting, mid-latitude storm forecasting, severe
weather analysis, and mid-level moisture estimation." (<a href="https://www.noaa.gov/jetstream/goes_east">NOAA</a>)</p>
<p>C01 <strong>Blue visible spectrum</strong></p>
<p>"The centralized wavelength for this band is 0.47 µm (micrometers).</p>
<p>Located in the blue portion of the visible spectrum, it provides
nearly continuous daytime observations of dust, haze, smoke, and clouds.
 It also includes measurements of "aerosol optical depths" that help air
 quality monitoring and tracking. Measurements in the blue band may
provide estimates of visibility as well." (<a href="https://www.noaa.gov/jetstream/goes_east">NOAA</a>)</p>
<hr />
<h1 id="using-the-framework">Using the framework</h1>
<p>The framework is modular and can be used to train and predict a wind speed for any day in the past data record that intersects between the operational use of the GOES16 satellite and scatterometer satellites. The channel used for the prediction and the model used can be selected by the user. <strong>For example : 2022-02-01 ResNet50, C01.</strong></p>
<p>Once a model has been trained on daily data, it can then be used to predict wind speed for any GOES image captured during daylight (temporal resolution : 10 mins).</p>
<p><img alt="1749563128189" src="../image/introduction/1749563128189.png" /></p>
<p><img alt="1749563221926" src="../image/introduction/1749563221926.png" /></p>
<p><img alt="1749563259236" src="../image/introduction/1749563259236.png" /></p>
<p>For each GOES wind speed prediction, buoy data and ERA5 are used as validation to verify the results from the model. See <em>"validation page"</em>.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>